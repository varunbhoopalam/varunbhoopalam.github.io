https://www.technologyreview.com/2020/03/13/905323/ai-lie-detectors-polygraph-silent-talker-iborderctrl-converus-neuroid/?utm_source=engagement_email&utm_medium=email&utm_campaign=site_visitor.unpaid.engagement&utm_term=editor-favorites&utm_content=12.20.subs&mc_cid=7baa7ebed7&mc_eid=56dbda6dfa

There is huge interest in the ability to detect deception. The limitations of polygraph tests are well known. There are now many projects and companies developed to produce deception detectors using AI/deep learning to develop complicated models to solve these problems. There are many criticisms of these technologies. In the article, critics often pointed to small training and test data sets that may show these technologies to be unreliable when put in real world settings outside of controlled labs with homogenous test subjects. Further, there is a lack of pyschological research that states that deception can be correlated to human behaviors that also can be generalized to all humans. There were also ethical and moral concerns regarding building products like these that could erode human trust, especially in cases where the model was incorrect. Because the science behind these technologies is not trusted with what the technologies are being used for, the article conveyed that we are far away from a legitimate lie detector.

I found it interesting that some companies were founded off of research insights. Like, X research was done to and now we have Y insight about the human behavior/science/other/etc. Is this a common pattern for companies? Have an insight and build technology around it that solves problems? Example from this article is research was produced to correlate behavior between emotions and mouse movements. Then someone built a company around it to detect fraud. 
